{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM and Sequence Generation\n",
    "\n",
    "In this notebook we're going to explore two changes to RNN we built in the previous notebook. \n",
    "\n",
    "1. The use of LSTM layers instead of SimpleRNN layers.\n",
    "2. Generating sequences instead of generating a single prediction as output.\n",
    "\n",
    "## LSTM\n",
    "\n",
    "A Long Short Term Memory layer is an extension of the RNN idea, and one that is designed to do 2 things:\n",
    "\n",
    "1. Give the hidden state more flexibillity in how it updates.\n",
    "2. Provide an efficent route for backpropagation, similar to skip layers in CNNs\n",
    "\n",
    "Here is a diagram from one of the readings [https://colah.github.io/posts/2015-08-Understanding-LSTMs/](https://colah.github.io/posts/2015-08-Understanding-LSTMs/):\n",
    "\n",
    "![](https://colah.github.io/images/post-covers/lstm.png)\n",
    "\n",
    "What you see here are the addition of several \"gates\" as well as an additional output from the layer compared to a simple RNN. Gates act like other hidden layers and have their own learned weights. \n",
    "\n",
    "The two states are called \"cell state\" (the top line) and \"hidden state\" the bottom line. Both serve a similar purpose to the RNN hidden state, but the cell state's progression doesn't involve an activation function over time which helps avoid the vanishing gradient problem that simple RNN's often suffer from.\n",
    "\n",
    "The gates are typically referred to as follows:\n",
    "\n",
    "**Forget gate**: The first gate uses a sigmoid activation to produce values between 0 and 1, those values are then pointwise multiplied with the incoming hidden state. This allows the cell state to \"forget\" irrelevant context when the activations are near 0. This gate is designed such that it can move the values in the cell state closer to zero.\n",
    "\n",
    "**Input and \"gate\" gates**: The second gate is a multiply and involves the sigmoid and tanh activations. The multiply gate allows the sigmoid to scales the tanh output. The result is a value between -1 and 1 which gets pointwise added to the cell state (after the forget is applied). This allows the cell state to incrementally learn new information and store it into the context. \n",
    "\n",
    "The sigmoid is called the \"input\" gate and the tanh is called the \"gate gate\" but they both work together to decide how much the cell state learns from the new input.\n",
    "\n",
    "**Output gate**: Finally, the last sigmoid is the output gate, and it scales the output next output and hidden state values, but not the cell state.\n",
    "\n",
    "## Sequence to sequence\n",
    "\n",
    "The next change we'll make is to allow multiple outputs over time, allowing us to generate text output from text input rather than a single output for classification or regression.\n",
    "\n",
    "![](https://karpathy.github.io/assets/rnn/diags.jpeg)\n",
    "\n",
    "This requires a few changes.\n",
    "\n",
    "1. First, the training data. We'll be using a setup where our inputs and labels will be from the exact same text, but at every timestep the label will be the word directly following the current word. \n",
    "2. Second we have to enable each timestep to produce a prediction.\n",
    "3. We have to map those numeric predictions to a word.\n",
    "4. We have to enable the network to stop somehow, we'll be allowing the network to generate as one of the \"words\" a \"stop\" token which when predicted will cause the network to stop.\n",
    "\n",
    "Note that this strategy works for generating text both character by character and word by word. We will be performing a character by character training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[20 49 58 59 60  3 17 49 60 49 66 45 54 12  2 16 45 46 55 58 45  3 63 45\n",
      "  3 56 58 55 43 45 45 44  3 41 54 65  3 46 61 58 60 48 45 58  8  3 48 45\n",
      " 41 58  3 53 45  3 59 56 45 41 51 10  2  2 15 52 52 12  2 33 56 45 41 51\n",
      "  8  3 59 56 45 41 51 10  2  2 20 49 58 59 60  3 17 49 60 49 66 45 54 12\n",
      "  2 39 55 61], shape=(100,), dtype=int64) \n",
      " b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "\n",
      "tf.Tensor(\n",
      "[49 58 59 60  3 17 49 60 49 66 45 54 12  2 16 45 46 55 58 45  3 63 45  3\n",
      " 56 58 55 43 45 45 44  3 41 54 65  3 46 61 58 60 48 45 58  8  3 48 45 41\n",
      " 58  3 53 45  3 59 56 45 41 51 10  2  2 15 52 52 12  2 33 56 45 41 51  8\n",
      "  3 59 56 45 41 51 10  2  2 20 49 58 59 60  3 17 49 60 49 66 45 54 12  2\n",
      " 39 55 61  3], shape=(100,), dtype=int64) \n",
      " b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "# load the tiny_shakespear dataset, 40,000 lines of text from various Shakspear plays\n",
    "# but only the \"train\" subset.\n",
    "dataset = tfds.load(name='tiny_shakespeare')['train']\n",
    "\n",
    "# Split the dataset from each line being a string to each line being an array of characters\n",
    "# in UTF-8 encoding\n",
    "dataset = dataset.map(lambda x: tf.strings.unicode_split(x['text'], 'UTF-8'))\n",
    "\n",
    "# Extract all the uniqe charcaters to form the vocabulary\n",
    "vocabulary = sorted(set(next(iter(dataset)).numpy()))\n",
    "\n",
    "# We're creating two functions to swap between characters and their int lookup value\n",
    "ids_from_chars = StringLookup(\n",
    "    vocabulary=list(vocabulary)\n",
    ")\n",
    "\n",
    "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True\n",
    ")\n",
    "\n",
    "# For training at each step we're asking the model to predict the next character\n",
    "# based on the current state + current character.\n",
    "dataset = dataset.map(lambda x: (ids_from_chars(x[:-1]), ids_from_chars(x[1:])))\n",
    "\n",
    "# Unbatch kind of flattens the data.\n",
    "# We're sort of implying that any line can flow fluidly into another line\n",
    "dataset = dataset.unbatch()\n",
    "\n",
    "# Now we're chopping the flat data into sequences of 100 characters each\n",
    "seq_len = 100\n",
    "dataset = dataset.batch(seq_len, drop_remainder = True)\n",
    "\n",
    "# We can see that \"next_char\" is just the \"cur_char\" shifted one position.\n",
    "# Because they are already encoded as UTF code points, they have a resaonblly efficent \n",
    "# numeric representation.\n",
    "for current_char, next_char in dataset.take(1):\n",
    "    print(current_char, '\\n', b''.join(chars_from_ids(current_char).numpy()))\n",
    "    print()\n",
    "    print(next_char, '\\n', b''.join(chars_from_ids(next_char).numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we're going to shuffle and batch it. Standard when working with Tensorflow's Dataset class\n",
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n",
    "\n",
    "Some things to note: \n",
    "\n",
    "1. We're using an LSTM rather than a simple RNN layer.\n",
    "2. It has a larger relative internal representation.\n",
    "3. The embedding dimension is similarly larger than last time.\n",
    "4. The output dimension is the size of the vocab (every unique character in the training data!)\n",
    "\n",
    "Also, we're actually subclassing the model class. This allows us to have a bit more control over when and how the layers talk to each other, and how we deal with state. Code slightly adapted from TF docs [https://www.tensorflow.org/tutorials/text/text_generation](https://www.tensorflow.org/tutorials/text/text_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[55 61 52 ... 12  3 65]\n",
      " [55 60  8 ... 59 49 47]\n",
      " [44 55 54 ... 46 59 41]\n",
      " ...\n",
      " [52 49 54 ... 44 45 10]\n",
      " [ 3 60 48 ...  3 60 48]\n",
      " [61 43 48 ... 58 45  3]], shape=(64, 100), dtype=int64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=ListWrapper([ListWrapper([InputSpec(shape=(64, 1024), ndim=2), InputSpec(shape=(64, 1024), ndim=2)]), ListWrapper([InputSpec(shape=(64, 1024), ndim=2), InputSpec(shape=(64, 1024), ndim=2)])]); however `cell.state_size` is [1024, 1024]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9fc467b9d515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_example_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_example_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_example_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mexample_batch_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_example_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_batch_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"# (batch_size, sequence_length, vocab_size)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9fc467b9d515>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, h_states, c_states, return_state, training)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Transfrom the embedding using lstm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# This is transformed output, transformed hidden state, and _ is hidden cell state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Pass the transformed x into the dense layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'constants'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   def call(self,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1006\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0;31m# initial_state was passed in call, check compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_state_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m       self.state_spec = [\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m_validate_state_spec\u001b[0;34m(cell_state_sizes, init_state_specs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_cell_state_sizes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_state_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mvalidation_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m     for cell_state_spec, cell_state_size in zip(flat_state_specs,\n\u001b[1;32m    622\u001b[0m                                                 flat_cell_state_sizes):\n",
      "\u001b[0;31mValueError\u001b[0m: An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=ListWrapper([ListWrapper([InputSpec(shape=(64, 1024), ndim=2), InputSpec(shape=(64, 1024), ndim=2)]), ListWrapper([InputSpec(shape=(64, 1024), ndim=2), InputSpec(shape=(64, 1024), ndim=2)])]); however `cell.state_size` is [1024, 1024]"
     ]
    }
   ],
   "source": [
    "class TextGeneratorModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # LSTM Second\n",
    "        self.lstm = tf.keras.layers.LSTM(rnn_units,\n",
    "                                       return_sequences=True, \n",
    "                                       return_state=True,\n",
    "                                        stateful=True)\n",
    "\n",
    "        # Dense last.\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, h_states=None, c_states=None, return_state=False, training=False):\n",
    "        # Transform the input using the embedding layer\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "\n",
    "        # If there is no incoming state from an earlier timestep\n",
    "        # use the default initial state behavior\n",
    "        if h_states is None:\n",
    "            h_states = self.lstm.get_initial_state(x)\n",
    "            \n",
    "        if c_states is None:\n",
    "            c_states = self.lstm.get_initial_state(x)\n",
    "        \n",
    "        # Transfrom the embedding using lstm\n",
    "        # This is transformed output, transformed hidden state, and _ is hidden cell state\n",
    "        x, h_states, c_states = self.lstm(x, initial_state=[h_states, c_states], training=training)\n",
    "\n",
    "        # Pass the transformed x into the dense layer\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        # Only return state when asked\n",
    "        if return_state:\n",
    "            return x, h_states, c_states\n",
    "        else: \n",
    "            return x\n",
    "\n",
    "\n",
    "# embedding output == 256, rnn units = 1024\n",
    "model = TextGeneratorModel(len(ids_from_chars.get_vocabulary()), 256, 1024)\n",
    "\n",
    "\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    print(input_example_batch)\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b' king to-day, my Lord of Derby?\\n\\nDERBY:\\nBut now the Duke of Buckingham and I\\nAre come from visiting '\n",
      "\n",
      "Predictions:\n",
      " b\"LP:D;e,feBOYXaqpMMUrG'?zHQAavq&P-AiAJRQxwBhPsvndd;'yU:qpCg!CR!vnw$he!tq DVAXm!&IsoQzR$REopSeM!BQIG\"\n"
     ]
    }
   ],
   "source": [
    "# Lets see what happens on the untrained network...\n",
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "\n",
    "print(\"Input:\\n\", b''.join(chars_from_ids(input_example_batch[0]).numpy()))\n",
    "print()\n",
    "print(\"Predictions:\\n\", b''.join(chars_from_ids(sampled_indices).numpy()))\n",
    "# Of course... a lot of garbage :)\n",
    "# But that's just because it's not trained... hopefully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 67)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         4.2039866\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "mean_loss = example_batch_loss.numpy().mean()\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", mean_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "156/156 [==============================] - 370s 2s/step - loss: 3.6661\n",
      "Epoch 2/20\n",
      "156/156 [==============================] - 334s 2s/step - loss: 3.1649\n",
      "Epoch 3/20\n",
      "156/156 [==============================] - 337s 2s/step - loss: 2.7907\n",
      "Epoch 4/20\n",
      "156/156 [==============================] - 340s 2s/step - loss: 2.5948\n",
      "Epoch 5/20\n",
      "156/156 [==============================] - 332s 2s/step - loss: 2.4945\n",
      "Epoch 6/20\n",
      "156/156 [==============================] - 339s 2s/step - loss: 2.4278\n",
      "Epoch 7/20\n",
      "156/156 [==============================] - 341s 2s/step - loss: 2.3723\n",
      "Epoch 8/20\n",
      "156/156 [==============================] - 316s 2s/step - loss: 2.3298\n",
      "Epoch 9/20\n",
      "156/156 [==============================] - 311s 2s/step - loss: 2.2844\n",
      "Epoch 10/20\n",
      "156/156 [==============================] - 311s 2s/step - loss: 2.2485\n",
      "Epoch 11/20\n",
      "156/156 [==============================] - 313s 2s/step - loss: 2.2160\n",
      "Epoch 12/20\n",
      "156/156 [==============================] - 333s 2s/step - loss: 2.1792\n",
      "Epoch 13/20\n",
      "156/156 [==============================] - 312s 2s/step - loss: 2.1527\n",
      "Epoch 14/20\n",
      "156/156 [==============================] - 316s 2s/step - loss: 2.1188\n",
      "Epoch 15/20\n",
      "156/156 [==============================] - 336s 2s/step - loss: 2.0946\n",
      "Epoch 16/20\n",
      "156/156 [==============================] - 321s 2s/step - loss: 2.0724\n",
      "Epoch 17/20\n",
      "156/156 [==============================] - 361s 2s/step - loss: 2.0425\n",
      "Epoch 18/20\n",
      "156/156 [==============================] - 333s 2s/step - loss: 2.0186\n",
      "Epoch 19/20\n",
      "156/156 [==============================] - 357s 2s/step - loss: 1.9966\n",
      "Epoch 20/20\n",
      "156/156 [==============================] - 355s 2s/step - loss: 1.9743\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    dataset, \n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text With The Model\n",
    "\n",
    "Using a model to generate text is done by using the outputs from the dense layer as a sampling distribution. At each step we run the model once, maintaining the state, sampling from the prediction, and then using our sampled character as input for the next timestep. Tensorflow's documentation has a wonderful visual and class to help us do this more easily, so we've stolen both. From [https://www.tensorflow.org/tutorials/text/text_generation](https://www.tensorflow.org/tutorials/text/text_generation)\n",
    "\n",
    "![](https://www.tensorflow.org/tutorials/text/images/text_generation_sampling.png)\n",
    "\n",
    "This strategy generates text of a fixed length, it's also common to encode a STOP token during training and generate text until our model samples that STOP token naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature=temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars(['','[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index.\n",
    "            values=[-float('inf')]*len(skip_ids),\n",
    "            indices = skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())]) \n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, h_states=None, c_states=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits] \n",
    "        predicted_logits, h_states, c_states =  self.model(inputs=input_ids, h_states=h_states, return_state=True)\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "        # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, h_states, c_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-19-5d45fa59188d>:27 generate_one_step  *\n        predicted_logits, h_states, c_states =  self.model(inputs=input_ids, h_states=h_states, return_state=True)\n    <ipython-input-4-cb5541d8efde>:28 call  *\n        x, h_states, c_states = self.lstm(x, initial_state=h_states, training=training)\n    /Users/tylerbettilyon/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:717 __call__  **\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /Users/tylerbettilyon/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/tylerbettilyon/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1157 call\n        inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n    /Users/tylerbettilyon/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:862 _process_inputs\n        raise ValueError('Layer has ' + str(len(self.states)) +\n\n    ValueError: Layer has 2 states but was passed 1 initial states.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d0734c6ddd44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnext_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_step_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3885\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-19-5d45fa59188d>:27 generate_one_step  *\n        predicted_logits, h_states, c_states =  self.model(inputs=input_ids, h_states=h_states, return_state=True)\n    <ipython-input-4-cb5541d8efde>:28 call  *\n        x, h_states, c_states = self.lstm(x, initial_state=h_states, training=training)\n    /Users/tylerbettilyon/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:717 __call__  **\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /Users/tylerbettilyon/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/tylerbettilyon/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1157 call\n        inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n    /Users/tylerbettilyon/.local/share/virtualenvs/intro-to-deep-learning-JEx0WlKO/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py:862 _process_inputs\n        raise ValueError('Layer has ' + str(len(self.states)) +\n\n    ValueError: Layer has 2 states but was passed 1 initial states.\n"
     ]
    }
   ],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n",
    "\n",
    "start = time.time()\n",
    "h_states = None\n",
    "c_states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, h_states, c_states = one_step_model.generate_one_step(next_char, h_states=h_states, c_states=c_states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "\n",
    "print(f\"\\nRun time: {end - start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
